{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tools.detect import MtcnnDetector\n",
    "\n",
    "in_path = \"org_data/\"\n",
    "out_path = \"preproc_data/\"\n",
    "\n",
    "data_path_list = [\n",
    "    \"re_train_neg_align/test_part/\",\n",
    "    \"re_train_neg_align/train_part/\",\n",
    "    \"re_train_pos_align/test_part/\",\n",
    "    \"re_train_pos_align/train_part/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(img, bboxs): # 【MD】bboxs:人脸区域\n",
    "    num_face = bboxs.shape[0]\n",
    "    h, w = img.shape[:2]\n",
    "    croped_bboxs = []\n",
    "    cropped = []\n",
    "    for i in range(num_face):\n",
    "        b_w = bboxs[i, 2] - bboxs[i, 0]\n",
    "        b_h = bboxs[i, 3] - bboxs[i, 1]\n",
    "        l_x = max(bboxs[i, 0] - 0.4 * b_w, 0)\n",
    "        l_y = max(bboxs[i, 1] - 0.4 * b_h, 0)\n",
    "        r_x = min(bboxs[i, 2] + 0.4 * b_w, w)\n",
    "        # r_y = min(bboxs[i, 3] + 0.4 * b_h, h)\n",
    "        r_y = bboxs[i, 3]\n",
    "        cb_0 = (0.4 * b_w) if bboxs[i, 0] > (0.4 * b_w)  else bboxs[i, 0]\n",
    "        cb_1 = (0.4 * b_h) if bboxs[i, 1] > (0.4 * b_h)  else bboxs[i, 1]\n",
    "        cb_2 = (1.4 * b_w) if bboxs[i, 0] > (0.4 * b_w)  else bboxs[i, 0] + b_w\n",
    "        cb_3 = cb_2 + b_h\n",
    "        cropped.append(img[int(l_y):int(r_y), int(l_x):int(r_x)])\n",
    "        croped_bboxs.append(int(cb_0))\n",
    "        croped_bboxs.append(int(cb_1))\n",
    "        croped_bboxs.append(int(cb_2))\n",
    "        croped_bboxs.append(int(cb_3))\n",
    "    return cropped , croped_bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-7cfe4ef1f3e4>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-7cfe4ef1f3e4>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    for i in range(num_imgs):\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mtcnn_detector = MtcnnDetector(min_face_size=24, use_cuda=False)\n",
    "    for i_path in range(len(data_path_list)):\n",
    "        data_path = data_path_list[i_path]\n",
    "        img_name_list = os.listdir(in_path+data_path)\n",
    "        num_imgs = len(img_name_list)\n",
    "        cropped_img_list = list()\n",
    "        cropped_bboxs_list = list()\n",
    "        img_list = list()\n",
    "        bboxs_list = list()\n",
    "        print(\"Now at Part \"+str(i_path)+\" of \"+str(len(data_path_list)+\" \"+ data_path + \" | number of imgs: \"+str(num_imgs))\n",
    "        \n",
    "        for i in range(num_imgs):\n",
    "            img_name = img_name_list[i]\n",
    "            print(\">>> Processing: \"+str(i)+\" of \"+str(num_imgs)+\" \"+data_path+img_name, end='\\r')\n",
    "            img = cv2.imread(in_path+data_path+img_name)\n",
    "            img_list.append(img)\n",
    "            bbox, _ = mtcnn_detector.detect_face(img)\n",
    "            bboxs_list.append(bbox)\n",
    "            cropped_img, cropped_bboxs = crop_images(img, bbox)\n",
    "            cropped_img_list.append(cropped_img)\n",
    "            cropped_bboxs_list.append(cropped_bboxs)\n",
    "        print(\"                                                                                       \")\n",
    "        print(\"=== Process \"+data_path+\" complete\")\n",
    "        # output\n",
    "#         os.mknod(\"\")\n",
    "        bboxs_file = open(out_path+data_path+\"bboxs_list.txt\", 'w')\n",
    "        cp_bboxs_file = open(out_path+data_path+\"cropped_bboxs_list.txt\", 'w')\n",
    "        \n",
    "        for i in range(num_imgs): # for every img\n",
    "            # save bboxs for every img\n",
    "            bboxs_file.write(img_name_list[i]+ ' '+ str(bboxs_list[i].shape[0])+ ' ')\n",
    "            \n",
    "            for b in range(bboxs_list[i].shape[0]): # number of faces in img[i]\n",
    "                img_file_name = str(b)+'_'+img_name_list[i]    \n",
    "                cv2.imwrite(out_path+data_path+img_file_name,cropped_img_list[i][b])\n",
    "                for n in range(bboxs_list[i].shape[1]): # number of coordinates of face[n]\n",
    "                    bboxs_file.write(str(bboxs_list[i][b, n])+' ')\n",
    "            bboxs_file.write('\\n')\n",
    "            # save cropped bbox coordinates for every img\n",
    "            cp_bboxs_file.write(img_name_list[i] + ' ' + str(bboxs_list[i].shape[0]) + ' ')\n",
    "            for position in cropped_bboxs_list[i]:\n",
    "                cp_bboxs_file.write(str(position) + ' ')\n",
    "            cp_bboxs_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
