@Apr 23rd
= 已完成
- 完成OpenCV-Cpp环境部署
- 完成features.cpp/void get_context_feature()编写与初步调试运行
	- 现void get_context_feature()已可以运行
		- 习得技能：OpenCV图像切割
		- 习得技能：OpenCV::calcHist()函数的参数设置
			- Hue: 图像色调，当色调为0时颜色即为黑色，255时为白色；
			- Saturation: 图像饱和度，当饱和度为0时，图像为灰度图；
		- 习得技能：以MatND格式存储直方图，并通过.at<float>(h_idx, s_idx)进行
			直方图各bin取值与赋值操作
- 完成anconda下OpenCV环境部署
= 待办项
- 直方图输出结果尚未与features.py中def get_context_feature()进行比对

@Apr 24nd
= 已完成
- 习得技能：OpenCV中需要InputArray与OutputArray对象的位置可直接使用Mat对象；

@Apr 25nd
= 习得技能：
- Python和C++中的OpenCV对裁剪图像用的ROI设定参数不同
	- Python中，cropped_img = img(左上x, 左上y, 右下x, 右下y)
	- C++中，Rect roi(左上x, 左上y, 宽, 高)
- 本以为用nonface_hist = face_hist初始化nonface_hist，但是face_hist会因此被改变，原因未知
	目前初始化采用：calcHist(&face, 1, channles, Mat(), nonface_hist, 1, histSize, ranges)
	- 【Apr 25nd 17:41】现已经改用nonface_hist = MatND::zeros(hbins,sbins,CV_32F)完成初始化
= 已完成
	- void get_context_feature()测试完成；
	- void get_lbp_feature()
		- 编写完成获取LBP特征部分，但由于计算方法与skimge中不同，是否有效仍待验证

@Apr 28nd
= 已完成
- void get_lbp_feature()完成编写与调试运行
	- 由于采用的Uniform LBP方法在计算上与Python源码中不同，故得到的直接结果有差异；
	- 考虑到之后会重新使用LIBSVM重新训练模型，故现在无视数值上的直接差异，仅进行直方图转化（保持与Python
	  源码相同的shape）
	- 使用cv::normalize()函数对直方图进行归一化
- 关于LIBSVM
	- 已将源代码下载至本地，实例代码可见LIBSVM目录下的svm-train.c和svm-predict.c
	- 具体使用还是得看README
	- 使用的话，将svm.h和svm.cpp加入已有代码中一起编译就可以使用LIBSVM的接口
- 功能拆分与对多文件的CMakeLists.txt编写，并编译通过
- 整理发布ReleaseVersion0.1.0
= 习得技能
- cv::normalize()
	- 注意其导出的MatND对象中，首位是归一化的总值；
- 关于头文件引入一事
	- 所有需要的#include<>语句都写在头文件里，这样.cpp直接include该头文件即可
- 关于对多文件的CMakeLists.txt文件的编写
	- 对于.h文件的引入：使用INCLUDE_DIRECTORIES(<path_to_headfile_directory>);
	- 如需制定当前CMakeLists.txt文件的位置，直接使用CMAKE_CURRENT_SOURCE_DIR变量，别用./指代当前目录
	- 若有多个.cpp需要编译，记得加入ADD_EXECUTABLE中，注意路径如上述；
= 下一阶段待办
- SVM Classifier
	- 获取训练用数据
	- 数据预处理
	- 使用LIBSVM构建模型
	- 进行训练
	- 进行预测

@May 3rd 13:04
= 开发计划
- SVM
	- 使用项目源码对数据集进行预处理，并导出特征集文件
		- 使用Python经过MTCNN得到crop_bbox
	- 直接用LIBSVM提供的接口进行模型的训练
		- 具体SVM的类型和超参的设置要研究下Python源码的设置
	- 在项目文件源码中只加入模型的预测功能
		- 调用LIBSVM关于模型载入与预测的接口
@May 3rd 20:25
= 已完成
- 使用Python完成对.cpp数据集的预处理
	- 源代码存放与./preprocess目录下
= 习得技能
- MTCNN可能在一张图片中检测出多张人脸，故mtcnn.detect_face()的返回值中，bboxs的0-dim表示检测到的人脸数
	- 对应的，crop_imges()也同样如此
- 使用CUDA_VISIBLE_DEVICES=x命令可在运行时指定GPU
	- EXAMPLE: CUDA_VISIBLE_DEVICES=4 python data_prepro.py 
- 使用cmd命令与服务器传输文件/目录
	- 从服务器下载目录：scp -r username@servername:<remote_dir> <local_dir>
	- 向服务器上传目录：scp -r <local_dir> username@servername:<remote_dir>
	- 从服务器下载文件：scp username@servername:<remote_file_path> <local_dir>
	- 从服务器下载文件：scp <local_file_path> username@servername:<remote_dir>
= 文件预处理结果说明
- 预处理后图片命名
	- x_<OrgFilename>.jpg
	- x为OrgFilename中检测到的第几张人脸
- bboxs_list.txt
	- 经过MTCNN模型进行人脸检测后得到的原图中人脸的位置坐标（左上角与右下角）
	- 各字段含义：
		- <org_file_name> <检测到人脸数> <人脸坐标_0：包括5个float> <人脸坐标_1：包括5个float> ...
- cropped_bboxs_list.txt
	- crop_images()函数对传入的人脸的位置进行放大后得到的选框对于原图的位置坐标（左上角与右下角）
	- 各字段含义：
		- <org_file_name> <检测到人脸数> <选框坐标_0: 包括4个int> <选框坐标_0: 包括4个int> ...

@May 4nd 13:34
= 今日第一坑
- 使用git获取remote上一本地尚未存在的分之时，先使用命令：
	- git checkout -b <local_new_branch_name> <remote_name>/<remote_branch_name>
	- 也就是现在本地新建一个分支，再从remote获取想要的分之进行覆盖
= 已完成
- svm_tools.cpp/void read_data()完成调试运行
= 优化点
- 特征提取时的MatND face_hist, nonface_hist, lbp_hist日后可以不分开，也就是弄一个长度为256+256+59的向量
	来保存，这样就可以省去之后的合并操作
@May 4nd 16:46
= 已完成
- 对data_preproc.py中的代码进行了更改
	- 现在输出的cropped_bbox格式为{xL,yL,w,h}
	- 由于原有crop_images()代码中构建crop_bbox的方法存在bug，导致输出的cropped_bbox范围大于裁剪后的图片，现
		已更正
- 完成svm_tools.cpp/preproc_data()的编写与调试运行
	- 功能概述：将read_data()中读入的struct data转为float的特征向量